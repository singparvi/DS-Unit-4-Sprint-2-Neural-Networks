{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJzTIkYAsLxw"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 2, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCf3jDMVQHuI"
   },
   "source": [
    "# Neural Network Frameworks (Prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GR0XBF5HQHuI"
   },
   "source": [
    "## Learning Objectives\n",
    "* <a href=\"#p1\">Part 1</a>: Implemenent Regularization Strategies\n",
    "* <a href=\"#p2\">Part 2</a>: Deploy a Keras Model\n",
    "* <a href=\"#p3\">Part 3</a>: Write a Custom Callback Function (Optional)\n",
    "\n",
    "Today's class will also focus heavily on Callback objects. We will use a variety of callbacks to monitor and manipulate our models based on data that our model produces at the end of an epoch.\n",
    "\n",
    "> A callback is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc). -- [Keras Documentation](https://keras.io/api/callbacks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWuoXZCCKCI7"
   },
   "source": [
    "# Regularization Strategies (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3aMJZuPQHur"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Neural Networks are highly parameterized models and can be easily overfit to the training data. The most salient way to combat this problem is with regularization strategies.  \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Regularization.svg/1920px-Regularization.svg.png)\n",
    "\n",
    "There are four common ways of regularization in neural networks which we cover briefly. Here's a quick summary of how to apply them: \n",
    "\n",
    "1. Always use EarlyStopping. This strategy will prevent your weights from being updated well past the point of their peak usefulness.\n",
    "2. Use EarlyStopping, Weight Decay and Dropout\n",
    "3. Use EarlyStopping, Weight Constraint and Dropout\n",
    "\n",
    "Weight Decay and Weigh Constraint accomplish similar purposes - preventing over fitting the parameters by regularizing the values. The mechanics are just slightly different. That's why you would not necessary want to apply them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FFhK0tLQHus"
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO74ukb-QHus"
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1622085648170,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     },
     "user_tz": 240
    },
    "id": "xgQR_iCHSF1x"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2874,
     "status": "ok",
     "timestamp": 1622085651238,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     },
     "user_tz": 240
    },
    "id": "t-xLR4Asmy3A",
    "outputId": "ae6dc8ad-be0f-41c8-eed8-01700a86d14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# load in our dataset \n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1622085651542,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     },
     "user_tz": 240
    },
    "id": "LErVFAGhnUaj",
    "outputId": "afc66b52-7aa4-4c1e-ee40-a17480697607"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_id = 500\n",
    "plt.imshow(X_train[image_id]);\n",
    "# plt.imshow(X_train[image_id], cmap='gray'); # to display in gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1622085651671,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     },
     "user_tz": 240
    },
    "id": "jY7KV_7xnip_"
   },
   "outputs": [],
   "source": [
    "# normalize pixel values between 0 and 1 \n",
    "max_pixel_value = 255\n",
    "X_train, X_test = X_train /max_pixel_value , X_test / max_pixel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3rIFGNWcwXP"
   },
   "source": [
    "### Build a Neural Network that uses EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "AY1HomhxQHus"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4734 - accuracy: 0.8282 - val_loss: 0.4015 - val_accuracy: 0.8537\n",
      "Epoch 2/99\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3547 - accuracy: 0.8689 - val_loss: 0.4072 - val_accuracy: 0.8472\n",
      "Epoch 3/99\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3192 - accuracy: 0.8818 - val_loss: 0.3627 - val_accuracy: 0.8699\n",
      "Epoch 4/99\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2969 - accuracy: 0.8895 - val_loss: 0.3427 - val_accuracy: 0.8772\n",
      "Epoch 5/99\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2817 - accuracy: 0.8951 - val_loss: 0.3523 - val_accuracy: 0.8744\n",
      "Epoch 6/99\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2682 - accuracy: 0.8993 - val_loss: 0.3585 - val_accuracy: 0.8756\n",
      "Epoch 7/99\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2567 - accuracy: 0.9036 - val_loss: 0.3421 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2b18b4610>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import ReLU\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# 1) Create 2 dir for logging files \n",
    "# create 2 dir -- one for tensorboard results and one for early stopping\n",
    "\n",
    "\n",
    "# 2) Instantiate the callbacks \n",
    "# instantiate a tensorboard callback object\n",
    "\n",
    "\n",
    "# instantiate a early stopping clallback object \n",
    "# docs: https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "\n",
    "# 3) Build the model \n",
    "\n",
    "# instantiate Sequential class\n",
    "\n",
    "# flatten images \n",
    "\n",
    "# hidden layer 1\n",
    "\n",
    "# act func 1\n",
    "\n",
    "# hidden layer 2\n",
    "\n",
    "# act func 2\n",
    "\n",
    "# hidden layer 3\n",
    "\n",
    "# act func 3\n",
    "\n",
    "# output layer \n",
    "\n",
    "# complie model \n",
    "\n",
    "# fit model \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create 2 dir -- one for tensorboard results and one for early stopping\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\") \n",
    "\n",
    "# instantiate a tensorboard callback object \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# instantiate a early stopping clallback object \n",
    "# docs: https://keras.io/api/callbacks/early_stopping/\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # takes 2D image and flattens into a row vector                         \n",
    "    Flatten(input_shape=(28,28)),\n",
    "    \n",
    "    Dense(128), # hidden layer 1 \n",
    "    ReLU(negative_slope=0.01), # act func 1\n",
    "    \n",
    "    Dense(128), # hidden layer 2 \n",
    "    ReLU(negative_slope=.01), # act func 2 \n",
    "    \n",
    "    Dense(128), # hidden layer 3 \n",
    "    ReLU(negative_slope=.01), # act func 3 \n",
    "    \n",
    "    Dense(10, activation='softmax') # output layer, use softmax for classification of labels greater than 2 \n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QiZkcUexq3_T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3420729637145996, 0.8799999952316284]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) # this is not the best in case you want the best \n",
    "# weight do the EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, \n",
    "# restore_best_weights=False); restore_best_weights=False is important to note\n",
    "\n",
    "# another one callback best one to use is ModelCheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MxOyH9AUq6i4"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7SkLOV087U9H"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "E3LFxeg1pJFE"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
       "            url.searchParams.set('tensorboardColab', 'true');\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7ScqKUzQHuv"
   },
   "source": [
    "---\n",
    "\n",
    "### Weight Decay (a.k.a Weight Shrinkage)\n",
    "\n",
    "```python\n",
    "Dense(64, input_dim=64,\n",
    "            kernel_regularizer=regularizers.l2(0.01),\n",
    "            activity_regularizer=regularizers.l1(0.01)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzHG6BvVQriY"
   },
   "source": [
    "![](https://qph.fs.quoracdn.net/main-qimg-9d0dbf8074761b541ba80543ddfc9f73.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlrWNqhHcwXQ"
   },
   "source": [
    "In the above image with the blue diamond and circle remember that: \n",
    "\n",
    "1. The X and Y axis represent possible values for model weights, in the case of this visualization we have w1 and w2. \n",
    "2. The red dot represents the trangent line (the point of contact) between the error surface (represented by the contour map) and the unit weights (represented by the blue shapes). \n",
    "3. The red dot also tells us the weight values at the point of contact. \n",
    "4. What determines the geometry of the blue shapes are their respective distance metrics. \n",
    "5. The norm of the weights determines where the point of contact will occur. And the norm of the weights is determined by which metric space **p** we are getting the norm equation from. \n",
    "\n",
    "$${\\displaystyle \\left\\|x\\right\\|_{p}=\\left(|x_{1}|^{p}+|x_{2}|^{p}+\\dotsb +|x_{n}|^{p}\\right)^{1/p}.}$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCCZa9TYQrsc"
   },
   "source": [
    "## Regularization Take Aways\n",
    "\n",
    "Almost remenber that:\n",
    "\n",
    "1. Ridge (l2) and Lasso (l1) are 2 out of possibily infinitly many ways to regularize a model by [**using a distiance metric in Lp space.**](https://en.wikipedia.org/wiki/Lp_space) \n",
    "\n",
    "2. Both L2 and L1 are used to help prevent overfitting. \n",
    "\n",
    "3. **The key difference between L1 and L2** is that L1 will calcualte zero valued feature weights (i.e. **w = 0**) for a subset of features; usually because redundent information is encoded in that subset of features; mathematically, this is refered to as [**MultiCollinearity**](https://en.wikipedia.org/wiki/Multicollinearity). Where as L2 will shrink the value of all feature weights but almost never down to zero. \n",
    "\n",
    "**Take Away: L1 drops features while L2 shrinks them and keeps them**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2pbTvNhQrvZ"
   },
   "source": [
    "![](https://i.stack.imgur.com/4KSgs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT3OD84MQrxq"
   },
   "source": [
    "The above image shows us the geometry of 4 specific Lp spaces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUPwXUgWcwXR"
   },
   "source": [
    "### Build a Neural Net using  $L^p$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQuacT-JQHuv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "# build a 3 hidden layer NN using Lp regularization and using both tensorboard and early stopping callbacks \n",
    "# create 2 dir -- one for tensorboard results and one for early stopping\n",
    "logdir = os.path.join(\"logs\", \"Weight-Decay-Loss\") \n",
    "\n",
    "# instantiate a tensorboard callback object \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# instantiate a early stopping clallback object \n",
    "# docs: https://keras.io/api/callbacks/early_stopping/\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, restore_best_weights=True)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # takes 2D image and flattens into a row vector                         \n",
    "    Flatten(input_shape=(28,28)),\n",
    "    \n",
    "    Dense(128, kernel_regularizer=regularizers.l2(0.01)), # hidden layer 1 \n",
    "    ReLU(negative_slope=0.01), # act func 1\n",
    "    \n",
    "    Dense(128, kernel_regularizer=regularizers.l2(0.01)), # hidden layer 2 \n",
    "    ReLU(negative_slope=.01), # act func 2 \n",
    "    \n",
    "    Dense(128, kernel_regularizer=regularizers.l2(0.01)), # hidden layer 3 \n",
    "    ReLU(negative_slope=.01), # act func 3 \n",
    "    \n",
    "    Dense(10, activation='softmax') # output layer, use softmax for classification of labels greater than 2 \n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXysik2_zSqT"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPA7EHOpxg2z"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XP12lHBnxFYe"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCJ1aUIfQHuy"
   },
   "source": [
    "----\n",
    "\n",
    "### Weight Constraint\n",
    "\n",
    "```python\n",
    "tf.keras.constraints.MaxNorm(\n",
    "    max_value=2, axis=0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frd__duGcwXS"
   },
   "source": [
    "![](https://qph.fs.quoracdn.net/main-qimg-9d0dbf8074761b541ba80543ddfc9f73.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9lmUjxtcwXT"
   },
   "source": [
    "What the weight constraint does is provide a maximum value for the normalized value of these weight norm shapes (represented by the mathematical notation at the buttom of each blue shape. The subscript (or superscript) indicates which $L^p$ space that norm was calculated in.\n",
    "\n",
    "$${\\displaystyle \\left\\|x\\right\\|_{p}=\\left(|x_{1}|^{p}+|x_{2}|^{p}+\\dotsb +|x_{n}|^{p}\\right)^{1/p}.}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbXBxr1QQHuy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import MaxNorm \n",
    "\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "# build a 3 hidden layer NN using Lp regularization and using both tensorboard and early stopping callbacks \n",
    "\n",
    "# build a 3 hidden layer NN using Lp regularization and using both tensorboard and early stopping callbacks \n",
    "# create 2 dir -- one for tensorboard results and one for early stopping\n",
    "logdir = os.path.join(\"logs\", \"MaxNorm-Loss\") \n",
    "\n",
    "# instantiate a tensorboard callback object \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# instantiate a early stopping clallback object \n",
    "# docs: https://keras.io/api/callbacks/early_stopping/\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, restore_best_weights=True)\n",
    "\n",
    "# weight constraint\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # takes 2D image and flattens into a row vector                         \n",
    "    Flatten(input_shape=(28,28)),\n",
    "    \n",
    "    Dense(128, kernel_constraint=wc), # hidden layer 1 \n",
    "    ReLU(negative_slope=0.01), # act func 1\n",
    "    \n",
    "    Dense(128, kernel_constraint=wc), # hidden layer 2 \n",
    "    ReLU(negative_slope=.01), # act func 2 \n",
    "    \n",
    "    Dense(128, kernel_constraint=wc), # hidden layer 3 \n",
    "    ReLU(negative_slope=.01), # act func 3 \n",
    "    \n",
    "    Dense(10, activation='softmax') # output layer, use softmax for classification of labels greater than 2 \n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Erf5T-nXziqc"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nfuTyj54Qjf"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-xMnXMsQHu0"
   },
   "source": [
    "-----\n",
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QszBfGEPcwXT"
   },
   "source": [
    "![](https://miro.medium.com/max/981/1*EinUlWw1n8vbcLyT0zx4gw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWa_kWNTcwXU"
   },
   "source": [
    "If interested, feel free to read through the original publication on [**Drop Out**](https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf). \n",
    "\n",
    "**Key Take aways:** \n",
    "\n",
    "1. During training, dropout will probabilistically \"turn off\" some neurons in the layer that dropout is implemented in. \n",
    "2. During inference (ie. making predictions on the test set) all neurons are used (i.e. no dropout is applied).\n",
    "3. Dropout works best when used with MaxNorm\n",
    "\n",
    "Here are some articel excepts on how dropout works. \n",
    "\n",
    "\"Dropout can be interpreted as a way of regularizing a neural network by adding noise to\n",
    "its hidden units.\" (page 2)\n",
    "\n",
    "\"Combining several models [model ensembles] is most\n",
    "helpful when the individual models are different from each other and in order to make\n",
    "neural net models different, they should either have different architectures or be trained\n",
    "on different data...It prevents overfitting and\n",
    "provides a way of approximately combining exponentially many different neural network\n",
    "architectures efficiently.\" (page 2)\n",
    "\n",
    "\"Training the **norm of the incoming weight vector** at each hidden unit to be upper\n",
    "bounded by a fixed constant c. In other words, if w represents the vector of weights incident\n",
    "on any hidden unit, the neural network was optimized under the constraint **||w||2 â‰¤ c**. \n",
    "\n",
    "This constraint was imposed during optimization by **projecting w onto the surface of a ball of\n",
    "radius c, whenever w went out of it**. This is also called **max-norm regularization** since it\n",
    "implies that the maximum value that the norm of any weight can take is c. The constant\n",
    "c is a tunable hyperparameter, which is determined using a validation set.\" (page 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCRL8SmgQHu0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFAkmZbVQHu2"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbV6zsdQQHu4"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will apply regularization strategies inside your neural network today, as you try to avoid overfitting it. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MXbzdBdURod"
   },
   "source": [
    "# Deploy (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11LJtU9MUVD5"
   },
   "source": [
    "## Overview\n",
    "\n",
    "You've built a dope image classification model, but it's just sitting your Jupyter Notebook. What now? Well you deploy to some down stream application. TensorFlow supports three ways of deploying it's models: \n",
    "\n",
    "- In-Browswer with TensorFlow.js\n",
    "- API with TensorFlow Serving (TFX) or another Framework\n",
    "- On-Device with TensorFlow Lite\n",
    "\n",
    "You are already familiar with deploying a model as an API from Unit 3, so we will focus on deploying a model in browser. Both methods rely on the same core idea: save your weights and architecture information, load those parameters into application, and perform inference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHca-4H2UU8p"
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP0IIAe4LFW5"
   },
   "source": [
    "### Checkpoint\n",
    "Save the latest weights of your model at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmtMJBBriD2Q"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h5\",\n",
    "                                            verbose=1, \n",
    "                                            save_weights_only=True)\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "          Flatten(input_shape=(28,28)),\n",
    "          Dense(128),\n",
    "          ReLU(negative_slope=.01),\n",
    "          Dense(128),\n",
    "          ReLU(negative_slope=.01),\n",
    "          Dense(128),\n",
    "          ReLU(negative_slope=.01),\n",
    "          Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=2, \n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[cpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5QoKB14LNMb"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eH9jo6gl-SMq"
   },
   "outputs": [],
   "source": [
    "# create a complied model and return it \n",
    "\n",
    "\n",
    "m = create_model()\n",
    "m.load_weights('./weights_best.h5')\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQl7g-ImLUY9"
   },
   "outputs": [],
   "source": [
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGzTQU1_Lnsb"
   },
   "source": [
    "### Save Entire Model\n",
    "This method includes both the weights and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXtxgTgYL0UC"
   },
   "outputs": [],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(X_train,y_train, epochs=5)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kURHysaUL87B"
   },
   "source": [
    "Load a fresh model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCgOlQalMIQr"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo8zSTTypNC4"
   },
   "outputs": [],
   "source": [
    "new_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYFdwhU4_Wm9"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i7OMOhzc6WT"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to be able to export your model weights and architecutre on the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXnXxPCZiAb2"
   },
   "source": [
    "# Custom Callbacks (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6vO6xbkiFGb"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Custom callbacks all you to access data at any point during the training: on batch end, on epoch end, on epoch start, on batch start. Our use case today is a simple one. Let's stop training once we reach a benchmark accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCocRF5CiYG_"
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOisQxYlibOi"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "Experiment with improving our custom callback function. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InClass_LS_DS_434_Deploy_Lecture.ipynb",
   "version": ""
  },
  "kernelspec": {
   "name": "u4-s1-nlp",
   "language": "python",
   "display_name": "U4-S1-NLP (Python3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 0
}