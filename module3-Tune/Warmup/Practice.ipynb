{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Practice.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "u4-s1-nlp",
   "language": "python",
   "display_name": "U4-S1-NLP (Python3)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu28mxQEkl27"
   },
   "source": [
    "# Objective 01 - describe the major hyperparameters to tune\n",
    "\n",
    "Neural networks have more parameters to tune than the other models we've worked with so far. Some of the most important ones are:\n",
    "\n",
    "batch size\n",
    "\n",
    "learning rate and number of training epochs\n",
    "\n",
    "activation function\n",
    "\n",
    "number of neurons in the hidden layer(s)\n",
    "\n",
    "optimization algorithms\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U59EVdQ0MovE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1621895615563,
     "user_tz": 240,
     "elapsed": 205,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     }
    },
    "outputId": "1ab053d7-cfbf-4ab3-bf22-73f38d3aa137"
   },
   "source": [
    "# Example modified from:\n",
    "# https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/\n",
    "\n",
    "# imports to create the classification\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# define the number of features\n",
    "num_features = 50\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "# binary classification (two classes)\n",
    "\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=num_features,\n",
    "                                       n_informative=2,\n",
    "                                       n_redundant=0,\n",
    "                                       n_classes=2,\n",
    "                                       weights=[.5, .5],\n",
    "                                       random_state=42\n",
    "                                       )\n",
    "\n",
    "# verify the size of the features and target\n",
    "print('Features array shape: ', features.shape)\n",
    "print('Target array shape: ', target.shape)\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features array shape:  (10000, 50)\nTarget array shape:  (10000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Moru8SxwPe2y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1621895619678,
     "user_tz": 240,
     "elapsed": 129,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     }
    }
   },
   "source": [
    "# Import keras models and layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# function to return a compiled network\n",
    "def make_network(optimizer='adam'):\n",
    "\n",
    "  # Instantiate a sequential model\n",
    "  network = models.Sequential()\n",
    "\n",
    "  # Add an input layer (shape=number of features)\n",
    "  network.add(layers.Dense(units=8, activation='relu', input_shape=(num_features,)))\n",
    "\n",
    "  # Add another hidden layer of 8 neurons\n",
    "  network.add(layers.Dense(units=8, activation='relu'))  # Activation function is like sigmoid function that does the squishing\n",
    "\n",
    "  # add an output layer with a sigmoid activation function\n",
    "  network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "  # Compile the network\n",
    "  network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                  optimizer=optimizer, # Optimizer\n",
    "                  metrics=['accuracy'] # Accuracy performance metric\n",
    "                  )\n",
    "  # Return the compiled network\n",
    "  return network\n",
    "\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vjLmrLfeSgV1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1621895619678,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     }
    }
   },
   "source": [
    "# Scikit-learn wrappers for keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "neural_network = KerasClassifier(build_fn=make_network, verbose=0) # This makes an object for sklearn classifier API, defining estimator for GridSearchCV"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "hrJF2aT0Tl6q",
    "executionInfo": {
     "status": "error",
     "timestamp": 1621895626340,
     "user_tz": 240,
     "elapsed": 6664,
     "user": {
      "displayName": "Parvi Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicHh9ECKPiyR68S3IUC3uvEPxQPh88MULwl8RHhQ=s64",
      "userId": "15870809085498692847"
     }
    },
    "outputId": "e77aed27-4619-4cdf-f07a-41d7abbca055"
   },
   "source": [
    "# Define the hyperparameter space over which to search\n",
    "epochs = [10, 25]\n",
    "batches = [4, 8, 32]\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "\n",
    "# make a dictionary of the parameters\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "\n",
    "# Create and fir the grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid =  GridSearchCV(estimator=neural_network, cv=5, param_grid=hyperparameters)\n",
    "grid_result = grid.fit(features, target)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'batch_size': 4, 'epochs': 25, 'optimizer': 'adam'}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# take a look at the best parameters\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilwXFmNtgZNv"
   },
   "source": [
    "# Objective 02 - implement an experiment tracking framework\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YLjgSJ9Rgb16"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# imports to create the classification and train test sets\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# define the number of features\n",
    "num_features = 50\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "# Binary classification\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                        n_features=num_features,\n",
    "                                        n_informative=3, \n",
    "                                        n_redundant=0,\n",
    "                                        n_classes=2,\n",
    "                                        random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# Specify the parameters and values\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 16]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Write the function to create the logs\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "    )"
   ]
  },
  {
   "source": [
    "# Adapt TensorFlow runs to log hyperparameters and metrics\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ6T0V7AUfg2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TFlZZgFjPp8n"
   },
   "source": [
    "# write the function to create the model with the\n",
    "# specified hyperparameter tuning\n",
    "\n",
    "def train_test_model(hparams):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "    model.fit(X_train, y_train, epochs=1)\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "source": [
    "# Log an hparams summary with the hyperparameters and final accuracy:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sQfiXfBUPYVB"
   },
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams) # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "source": [
    "# Start runs and log them all under one parent directory\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dfXGngg2O02o"
   },
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 417us/step - loss: 2.0910 - accuracy: 0.2760\n",
      "79/79 [==============================] - 0s 371us/step - loss: 1.3255 - accuracy: 0.4712\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 382us/step - loss: 1.2719 - accuracy: 0.6231\n",
      "79/79 [==============================] - 0s 371us/step - loss: 0.7844 - accuracy: 0.7572\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 437us/step - loss: 1.6082 - accuracy: 0.4537\n",
      "79/79 [==============================] - 0s 381us/step - loss: 1.0086 - accuracy: 0.6808\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 391us/step - loss: 1.3732 - accuracy: 0.5516\n",
      "79/79 [==============================] - 0s 380us/step - loss: 0.7840 - accuracy: 0.7548\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 488us/step - loss: 1.7410 - accuracy: 0.4619\n",
      "79/79 [==============================] - 0s 379us/step - loss: 0.8690 - accuracy: 0.7328\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 404us/step - loss: 1.2667 - accuracy: 0.5892\n",
      "79/79 [==============================] - 0s 364us/step - loss: 0.6682 - accuracy: 0.7700\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 462us/step - loss: 1.3869 - accuracy: 0.5260\n",
      "79/79 [==============================] - 0s 368us/step - loss: 0.6881 - accuracy: 0.7752\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 414us/step - loss: 1.4908 - accuracy: 0.4535\n",
      "79/79 [==============================] - 0s 365us/step - loss: 0.7794 - accuracy: 0.7272\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D0t_aN_PNOFC"
   },
   "source": [
    "HP_NUM_UNITS.domain.values, HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, "
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([8, 16], 0.1, 0.2)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "source": [
    "# Visualize the results in TensorBoard's HParams plugin\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%git` not found.\n"
     ]
    }
   ],
   "source": [
    "%git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}